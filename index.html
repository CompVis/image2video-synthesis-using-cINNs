<!DOCTYPE HTML>
<!--
  Based on
	Spatial by TEMPLATED
	templated.co @templatedco
	Released for free under the Creative Commons Attribution 3.0 license (templated.co/license)
-->
<html>
	<head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117339330-4"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-117339330-4');
    </script>

    <title>
      Stochastic Image-to-Video Synthesis using cINNs
    </title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="landing">

		<!-- Banner -->
			<section id="banner" style="background-attachment:scroll;">
        <h2>
          Stochastic Image-to-Video Synthesis using cINNs
        </h2>
        <p>
        <a href="https://mdork.github.io/">Michael Dorkenwald</a><sup>1</sup>,
        <a href="hhttps://timomilbich.github.io/">Timo Milbich</a><sup>1</sup>,
        <a href="https://www.linkedin.com/in/andreas-blattmann-479038186/?originalSubdomain=de">Andreas Blattmann</a><sup>1</sup>,
        <a href="https://github.com/rromb">Robin Rombach</a><sup>1</sup>,
        <a href="https://www.cs.ryerson.ca/kosta/">Konstantinos G. Derpanis</a><sup>2,3,4</sup>,
        <a href="https://hci.iwr.uni-heidelberg.de/Staff/bommer">Bj&ouml;rn Ommer</a><sup>1</sup><br/>
        <sup>1</sup><a href="https://www.iwr.uni-heidelberg.de/">IWR/HCI, Heidelberg University, Germany</a>
        <sup>2</sup><a href="https://ryersonvisionlab.github.io/">Department of Computer Science, Ryerson University, Canada</a><br/>
        <sup>3</sup><a href="https://vectorinstitute.ai/">Vector Institute for AI, Canada</a>
        <sup>4</sup><a href="https://research.samsung.com/aicenter_toronto">Samsung AI Centre Toronto, Canada</a> <br/>
        Accepted at <a href="http://cvpr2021.thecvf.com/">CVPR 2021</a><br/>
        </p>
			</section>

			<!-- One -->
				<section id="one" class="wrapper style1">
					<div class="container 75%">

						<div class="row 200%">
							<div class="6u 12u$(medium) vert-center" style="margin:1% 0">
                  <div class="container 25%">


                    <div class="image fit captioned align-center"
                                style="margin-bottom:0em; box-shadow:0 0">
                      <a href="paper/paper.pdf">
                        <img src="paper/paper.png" alt="" style="border:1px solid black"/>
                      </a>
                      <a href="https://arxiv.org/abs/2103.04677">arXiv</a>
                      <div class="headerDivider"></div>
                      <a href="paper/paper.bib">BibTeX</a>
                      <div class="headerDivider"></div>
                      <a href="https://github.com/CompVis/behavior-driven-video-synthesis">GitHub</a>
                      <br/>
                      <!-- &ast; indicates equal contribution -->
                    </div>

                  </div>
							</div>
							<div class="6u$ 12u$(medium)">
                <h1>Abstract</h1>
                <p style="text-align: justify">
                Video understanding calls for a model to learn the characteristic interplay between static scene content and its dynamics: Given an image, the model must be able to predict a future progression of the portrayed scene and, conversely, a video should be explained in terms of its static image content and all the remaining characteristics not present in the initial frame. This naturally suggests a bijective mapping between the video domain and the static content as well as residual information. In contrast, to common stochastic image-to-video synthesis, such a model does not merely generate arbitrary videos progressing the initial image. Given this image, it rather provides a one-to-one mapping between the residual vectors and the video with stochastic outcomes when sampling. The approach is naturally implemented using a conditional invertible neural network (cINN) that can explain videos by independently modelling static and other video characteristics, thus laying the basis for controlled video synthesis. Experiments on diverse video datasets demonstrate the effectiveness of our approach in terms of both the quality and diversity of the synthesized results.
                </p>

							</div>
						</div>

				</section>


			<!-- Two -->
				<section id="two" class="wrapper style2 special">
					<div class="container">
						<header class="major">
							<h2>Arpproach</h2>
						</header>

            <div class="row 150%">
            	</section>

			<!-- One -->
				<section id="one" class="wrapper style1">
					<div class="container 75%">
												<div class="image fit captioned align-left"
                                style="margin-bottom:2em; box-shadow:0 0;
                                text-align:justify">
                      <img src="images/method.png" alt="" style="border:0px solid black"/>
                      Overview of our proposed framework. We learn an information preserving video representation $z$ using our conditional generative model consisting of an encoder $q_\phi$ as well as the corresponding decoder $p_\psi$. The decoder consists of dedicated video residual blocks shown in right bottom. 
    
					    After establishing the video representation, we learn a bijective transformation $\mathcal{T}$ conditioned on the starting frame $x_0$ and an optionally provided control factor $\eta$.
					    During inference, we sample a residual $\nu$, encapsulating the scene dynamics, from the prior distribution and use $\mathcal{T}_\phi$ to obtain the video representation $z$. Using our decoder we can then synthesize novel video sequences. Training and inference is indicated by the yellow dotted and purple solid lines.
                    </div>
            <div class="row 150%">
            	</section>
        <section id="two" class="wrapper style2 special">
          <div class="container">
            <header class="major">
              <h2>Results</h2>
            </header>


<header class="minor">
  <h3>Results on Landscape</h3>
</header>

<div class="row 150%">
<div class="6u 12u$(xsmall)">


<div class="image fit captioned align-just">
<div class="videocontainer">
<video controls class="videothing">
<source src="images/Landscape_samples.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
</div>
Samples
</div>
</div>
<div class="6u$ 12u$(xsmall)">

<div class="image fit captioned align-just">
<div class="videocontainer">
<video controls class="videothing">
<source src="images/Landscape_diversity.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
</div>
Diversity
</div>
</div>
</div>


<div class="row 250%">
<div class="6u 12u$(xsmall)">

<div class="image fit captioned align-just">
<div class="videocontainer">
<video controls class="videothing">
<source src="images/Landscape_comparison.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
</div>
Comparison with other works.
</div>
</div>
<div class="6u$ 12u$(xsmall)">

<div class="image fit captioned align-just">
<div class="videocontainer">
<video controls class="videothing">
<source src="images/longer_duration.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
</div>
Longer samples
</div>
</div>
</div>


<header class="minor">
  <h3>Results on iPER</h3>
</header>

<div class="row 250%">
<div class="6u 12u$(xsmall)">
	
<div class="image fit captioned align-just">
<div class="videocontainer">
<video controls class="videothing">
<source src="images/iPER_samples.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
</div>
Samples
</div>
</div>
<div class="6u$ 12u$(xsmall)">

<div class="image fit captioned align-just">
<div class="videocontainer">
<video controls class="videothing">
<source src="images/iPER_comparison.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
</div>
Comparison
</div>
</div>
</div>

<header class="minor">
  <h3>Results on BAIR</h3>
</header>

<div class="row 250%">
<div class="6u 12u$(xsmall)">

<div class="image fit captioned align-just">
<div class="videocontainer">
<video controls class="videothing">
<source src="images/BAIR_comparison.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
</div>
BAIR comparison.
</div>
</div>
<div class="6u$ 12u$(xsmall)">

<div class="image fit captioned align-just">
<div class="videocontainer">
<video controls class="videothing">
<source src="images/BAIR_diversity.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
</div>
Diversity
</div>
</div>
</div>

<header class="minor">
  <h3>Results on Dynamic Textures (DTDB)</h3>
</header>

<div class="row 250%">
<div class="6u 12u$(xsmall)">
	
<div class="image fit captioned align-just">
<div class="videocontainer">
<video controls class="videothing">
<source src="images/Fire.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
</div>
Fire
</div>
</div>
<div class="6u$ 12u$(xsmall)">

<div class="image fit captioned align-just">
<div class="videocontainer">
<video controls class="videothing">
<source src="images/vegetation.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
</div>
Vegetation
</div>
</div>
</div>

<div class="row 250%">
<div class="6u 12u$(xsmall)">
	
<div class="image fit captioned align-just">
<div class="videocontainer">
<video controls class="videothing">
<source src="images/Waterfall.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
</div>
Waterfall
</div>
</div>
<div class="6u$ 12u$(xsmall)">

<div class="image fit captioned align-just">
<div class="videocontainer">
<video controls class="videothing">
<source src="images/Clouds.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
</div>
Clouds
</div>
</div>
</div>



<header class="minor">
  <h3>Results on Controlled Video Synthesis</h3>
</header>

<div class="row 250%">
<div class="6u 12u$(xsmall)">
	
<div class="image fit captioned align-just">
<div class="videocontainer">
<video controls class="videothing">
<source src="images/Transfer_Landscape.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
</div>
Transfer on Landscape
</div>
</div>
<div class="6u$ 12u$(xsmall)">

<div class="image fit captioned align-just">
<div class="videocontainer">
<video controls class="videothing">
<source src="images/Direction_Clouds1.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
</div>
Clouds controlled image-to-video synthesis
</div>
</div>
</div>


<div class="row 250%">
<div class="6u 12u$(xsmall)">
	
<div class="image fit captioned align-just">
<div class="videocontainer">
<video controls class="videothing">
<source src="images/Direction_Clouds2.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
</div>
Clouds controlled video-to-video synthesis
</div>
</div>
<div class="6u$ 12u$(xsmall)">
<div class="image fit captioned align-just">
<div class="videocontainer">
<video controls class="videothing">
<source src="images/Endpoint_BAIR.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
</div>
BAIR endpoint
</div>
</div>
</div>


<!-- related works ! -->

				<section id="one" class="wrapper style1">
					<div class="container 85%">
						<div class="row 250%">
<div class="12u">
  <h4> Our Related Work on Video Synthesis</h4>
</div>

<div class="12u">
  <h6>
    <a href="https://compvis.github.io/behavior-driven-video-synthesis/">
      Behavior-Driven Synthesis of Human Dynamics
    </a>
  </h6>
</div>
<div class="3u 12u$(medium)">
  <div class="image fit align-center">
    <a href="https://compvis.github.io/behavior-driven-video-synthesis/">
      <img src="images/teaser_behavior.png" style="max-width:25em; margin:auto" />
    </a>
  </div>
</div>
<div class="9u 12u$(medium)">
  <p align="justify" style="line-height: 1.0em; font-size:0.8em">
  Generating and representing human behavior are of major importance for various computer vision applications. Commonly, human video synthesis represents behavior as sequences of postures while directly predicting their likely progressions or merely changing the appearance of the depicted persons, thus not being able to exercise control over their actual behavior during the synthesis process. In contrast, controlled behavior synthesis and transfer across individuals requires a deep understanding of body dynamics and calls for a representation of behavior that is independent of appearance and also of specific postures. In this work, we present a model for human behavior synthesis which learns a dedicated representation of human dynamics independent of postures. Using this representation, we are able to change the behavior of a person depicted in an arbitrary posture, or to even directly transfer behavior observed in a given video sequence. To this end, we propose a conditional variational framework which explicitly disentangles posture from behavior. We demonstrate the effectiveness of our approach on this novel task, evaluating capturing, transferring, and sampling fine-grained, diverse behavior, both quantitatively and qualitatively.
</div>
</div>
</div>

 <!-- /related works ! -->
						</div>
				</section>


			<!-- Four -->
				<section id="four" class="wrapper style3 special"
          style="background-attachment:scroll;background-position:center bottom;">
					<div class="container">
						<header class="major">
							<h2>Acknowledgement</h2>
              <p>
              	This work was started as part of M.D.’s internship at Ryerson University and was supported by the DAAD scholarship, funded by the NSERC Discovery Grantprogram (K.G.D.), in part by the German Research Foundation (DFG) within project 421703927 (B.O.) and the BW Stiftung (B.O.). K.G.D. contributed to this work in his capacity as an Associate Professorat Ryerson University.
              This page is based on a design by <a href="http://templated.co">TEMPLATED</a>.
              </p>
						</header>
					</div>
				</section>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
